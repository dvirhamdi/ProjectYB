import numpy as np
import HD
import pickle
import os


class Danse():
    def __init__(self,n,inputs):

        self.inputs = 0
        self.weights = 1 * np.random.random((inputs, n)) - 1
        self.biass = np.zeros((n))

    def setW(self,W):
        if self.weights.shape == W.shape:
            self.weights = W
        else:
            raise ValueError('shapes must be the same!')


    # The Sigmoid function, which describes an S shaped curve.
    # We pass the weighted sum of the inputs through this function to
    # normalise them between 0 and 1.
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))


    # The neural network thinks.
    def think(self, inputs):
        self.inputs = inputs
        # Pass inputs through our neural network (our single neuron).
        return self.sigmoid(np.dot(inputs, self.weights) + self.biass)


class Model():
    def __init__(self):
        self.layers = []


    def add(self,layer):
        self.layers.append(layer)


    def train(self,x,y,epochs = 100):
        for e in range(epochs):
            output = self.prdict(x)
            #output = np.clip(output,1e-5, 1 - 1e-5)
            print(f'epochs:{e},loss:{self.mse(pred = output,true=y)}')
            for i,lay in enumerate(reversed(self.layers)):

                error = self.mse(pred = output,true=y)

                lay.weights -= 0.01*(-2*np.dot(lay.inputs.T,(y-output))/y.shape[0])
                lay.biass -= 0.01*(2*np.sum(y-output)/y.shape[0])

                #print('a',lay.inputs.T,i)
                output = lay.inputs


    def mse(self,pred,true):
        return np.mean((pred-true)**2)

    def mse_derivative(self,x):
        pass

    def prdict(self,x):
        t = x
        for lay in self.layers:
            t = lay.think(t)

        return t

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))


    def sigmoid_derivative(self, x):
        return self.sigmoid(x) * (1 - self.sigmoid(x))

    def evaluate(self,X_test,y_test):
        print(y_test[0])
        pred = self.prdict(X_test)
        pred = np.round(pred)

        score = np.where(pred[0] == np.array(y_test[0]))
        return len(score[0])/len(y_test[0])

    def save(self,path):
        W = []
        for lay in self.layers:
            W.append(lay.weights)

        pickle.dump(W,open(path+'.p','wb'))

    def load(self,path):
        W = pickle.load(open(path,'rb'))
        for i,w in enumerate(W):
            self.layers[i].setW(w)


        

layer1 = Danse(n=128,inputs=128*128)
layer2 =  Danse(n=1,inputs=128)
model = Model()

model.add(layer1)
model.add(layer2)

X_train, X_test, y_train, y_test = HD.get_data(r'D:\cyber\yb project\databases\photos')


#X_train,X_test = HD.scale_data(X_train,X_test)


model.train(X_train,y_train.T,epochs=1000)


print('model trained!')
os.chdir(r'C:\Users\Dvir hamdi\PycharmProjects\cyberHW\yodbet project')


model.save('model')
model.load('model.p')
# Test the neural network with a new situations.
print('acc:',model.evaluate(X_test,y_test)*100,'%')
